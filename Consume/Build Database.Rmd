---
title: "Build Database"
author: "David Ory"
output: 
   html_document:
      theme: cosmo
      toc: yes
---

## Administration

#### Purpose
This script consumes Rupinder's Caltrans traffic count files.  The data is melted into a simpler database format and outlier counts are identified and removed. 

#### Outputs
1.  A consolidated database of clean Caltrans counts for typical weekdays

#### TODO
1.  Build tableau
2.  Move back a step in the sequence?


## Procedure

#### Overhead
```{r overhead, results = 'hide'}
library(knitr)
library(reshape2)
suppressMessages(library(dplyr))
library(timeDate)
library(chron)
```

```{r config, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

#### Remote IO Locations
```{r remote-io}
F_INPUT_DIR = "~DavidWork/Documents/"
INPUT_FILE  = "98_13_PMwithdecimal_no_single.txt"

F_OUTPUT_DIR = "~DavidWork/Documents/"
OUTPUT_FILE = "typical-weekday-counts-1998-2013.csv"
```

#### Parameters
```{r parameters}
# Relevant holidays database
HOLIDAY_LIST  <- c("USLaborDay", "USMemorialDay", "USThanksgivingDay", "USVeteransDay")
HOLIDAY_DATES <- dates(as.character(holiday(1998:2020, HOLIDAY_LIST)), format = "Y-M-D")

# Minimum number of days observed for estimates to be retained
MIN_DAYS_OBSERVED = 15
```


#### Data reads
```{r data-reads}
input_file_name <- paste(F_INPUT_DIR, INPUT_FILE, sep = "")
input_df <- read.table(file = input_file_name, header = TRUE, sep = ",", stringsAsFactors = FALSE, strip.white = TRUE)

```

#### Data cleaning
```{r data-cleaning}
# select the variables of interest
clean_df <- input_df %>%
  select(route = ROUTE, 
         county = COUNTY, 
         post_mile = PM, 
         leg = LEG, 
         direction = DIR, 
         station = STATION,
         description = DESCRIP, 
         date_string = date,
         END1AM, END2AM, END3AM, END4AM, END5AM, END6AM, END7AM, END8AM, END9AM, END10AM, END11AM, END12NOO,
         END1PM, END2PM, END3PM, END4PM, END5PM, END6PM, END7PM, END8PM, END9PM, END10PM, END11PM, END12NIG)

# Melt
clean_df <- melt(clean_df, id = c("route", "county", "post_mile", "leg", 
                                  "direction", "station", "description", "date_string"))

# Tidy-up the melt
clean_df <- clean_df %>%
  rename(count = value) %>%
  mutate(integer_hour = 
           (variable == 'END1AM')  * 1 +
           (variable == 'END2AM')  * 2 +
           (variable == 'END3AM')  * 3 +
           (variable == 'END4AM')  * 4 +
           (variable == 'END5AM')  * 5 +
           (variable == 'END6AM')  * 6 +
           (variable == 'END7AM')  * 7 +
           (variable == 'END8AM')  * 8 +
           (variable == 'END9AM')  * 9 +
           (variable == 'END10AM') * 10 +
           (variable == 'END11AM') * 11 +
           (variable == 'END12NOO') * 12 +
           (variable == 'END1PM')  * 13 +
           (variable == 'END1PM')  * 14 +
           (variable == 'END2PM')  * 15 +
           (variable == 'END3PM')  * 16 +
           (variable == 'END4PM')  * 17 +
           (variable == 'END5PM')  * 18 +
           (variable == 'END6PM')  * 19 +
           (variable == 'END7PM')  * 20 +
           (variable == 'END8PM')  * 21 +
           (variable == 'END9PM')  * 22 +
           (variable == 'END10PM') * 23 +
           (variable == 'END11PM') * 24 +
           (variable == 'END12NIG') * 0) %>%
  select(-variable)

# Create typical weekday flag
clean_df <- clean_df %>%
  mutate(date = as.Date(date_string, format = "%d%B%y")) %>%
  mutate(day_of_week = weekdays(date)) %>%
  mutate(typical_day_of_week = (day_of_week == "Tuesday") * 1 + 
           (day_of_week == "Wednesday") * 1 + 
           (day_of_week == "Thursday") * 1) %>%
  mutate(month = months(date)) %>%
  mutate(typical_month = (month == "March") * 1 +
           (month == "April") * 1 +
           (month == "May") * 1 +
           (month == "September") * 1 +
           (month == "October") * 1 +
           (month == "November") * 1) %>%
  mutate(not_holiday = !(is.holiday(date, HOLIDAY_DATES))) %>%
  mutate(typical_weekday = typical_day_of_week * typical_month * not_holiday) %>%
  select(-day_of_week, -typical_day_of_week, -month, -typical_month, -not_holiday)

# Typical weekday summaries
typical_sum_df <- clean_df %>%
  filter(typical_weekday == 1) %>%
  group_by(route, county, post_mile, leg, direction, station, description, integer_hour) %>%
  summarise(median_count = median(count), avg_count = mean(count), sd_count = sd(count), days_observed = n())

# Join typical weekday stats to each record
typical_df <- clean_df %>%
  filter(typical_weekday == 1)

typical_df <- left_join(typical_df, typical_sum_df, by = c("route", "county", "post_mile", "leg", "direction", "station", "description", "integer_hour"))

# Flag suspect counts
typical_df <- typical_df %>%
  mutate(three_sd_low  = avg_count - 4 * sd_count) %>%
  mutate(three_sd_high = avg_count + 4 * sd_count) %>%
  mutate(suspect_flag = (count < three_sd_low) + (count > three_sd_high))

table(typical_df$suspect_flag)

# Remove suspects and small sample size, redo summaries
typical_sum_df <- typical_df %>%
  filter(suspect_flag == 0) %>%
  group_by(route, county, post_mile, leg, direction, station, description, integer_hour) %>%
  summarise(median_count = median(count), avg_count = mean(count), 
            sd_count = sd(count), days_observed = n()) %>%
  filter(days_observed > MIN_DAYS_OBSERVED)

```

#### Write to disk
```{r data-writes}
output_file_name <- paste(F_OUTPUT_DIR, OUTPUT_FILE, sep = "")
write.csv(typical_sum_df, file = output_file_name, row.names = FALSE, quote = T)
```

